{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "As we can see, we can't ignore punctuation. Moreover, there can be also special characters we need to take into account, such as `#`, `$`, `%`, etc. Raw text is typically not well suited for analyzis. The text preprocessing usually incorporate a cleaning step, including\n",
    "\n",
    "* converting everything to lower case\n",
    "* remove line breaks\n",
    "* removing punctuation\n",
    "* removing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "tar_path = \"/home/elahe/Desktop/UniPisa/IR/Project/TinTinfy/collection.tar.gz\"  \n",
    "output_file = \"preprocessed_data.json\"\n",
    "\n",
    "# Extract the tar.gz file\n",
    "#with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "#   tar.extractall()\n",
    "\n",
    "# Process the extracted file\n",
    "input_file = \"collection.tsv\"  # The extracted file name\n",
    "preprocessed_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North-American wildlife RockR Wildlife isimportant\n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Remove punctuation except for intra-word hyphens\n",
    "    return re.sub(r'[^\\w\\s-]', '', text)\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"North-American wildlife, Rock&R Wildlife is—important!\"\n",
    "print(remove_punctuation(sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2023, there were  species and  -  migrations.\n"
     ]
    }
   ],
   "source": [
    "def remove_numbers_keep_dates(text):\n",
    "    # Keep years or dates in the format YYYY or MM-DD\n",
    "    return re.sub(r'\\b(?!\\d{4}\\b|\\d{1,2}-\\d{1,2})\\d+\\b', '', text)\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"In 2023, there were 15 species and 12 - 25 migrations.\"\n",
    "print(remove_numbers_keep_dates(sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canciÃ3n doesnât Â©\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def fix_encoding_issues(text):\n",
    "    # Normalize text to handle encoding issues\n",
    "    return unicodedata.normalize('NFKD', text)\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"canciÃ³n doesnât Â©\"\n",
    "print(fix_encoding_issues(sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1 Line 2 Line 3.\n"
     ]
    }
   ],
   "source": [
    "def remove_line_breaks(text):\n",
    "    # Replace line breaks with a single space\n",
    "    return text.replace('\\n', ' ')\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"Line 1\\nLine 2\\nLine 3.\"\n",
    "print(remove_line_breaks(sample_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVT WILDLIFE wildlife is important for the US and CVT ecosystem.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preserve_case(text):\n",
    "    # Split the text into tokens\n",
    "    tokens = text.split()\n",
    "    # Convert tokens to lowercase unless they are all uppercase\n",
    "    processed_tokens = [token if token.isupper() else token.lower() for token in tokens]\n",
    "    # Join tokens back into a string\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"CVT WILDLIFE Wildlife is important for the US and CVT ecosystem.\"\n",
    "print(preserve_case(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/elahe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define helper functions\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = remove_punctuation(text)\n",
    "    text = preserve_case(text)\n",
    "    text = remove_numbers_keep_dates(text)\n",
    "    text = fix_encoding_issues(text)\n",
    "    text = remove_line_breaks(text)\n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Apply stemming\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canciã3n doesnât â'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(\"canciÃ³n doesnât Â©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw file content (first 5 lines):\n",
      "['0', 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.']\n",
      "['1', 'The Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.']\n",
      "['2', 'Essay on The Manhattan Project - The Manhattan Project The Manhattan Project was to see if making an atomic bomb possible. The success of this project would forever change the world forever making it known that something this powerful can be manmade.']\n",
      "['3', 'The Manhattan Project was the name for a project conducted during World War II, to develop the first atomic bomb. It refers specifically to the period of the project from 194 â\\x80¦ 2-1946 under the control of the U.S. Army Corps of Engineers, under the administration of General Leslie R. Groves.']\n",
      "['4', 'versions of each volume as well as complementary websites. The first websiteâ\\x80\\x93The Manhattan Project: An Interactive Historyâ\\x80\\x93is available on the Office of History and Heritage Resources website, http://www.cfo. doe.gov/me70/history. The Office of History and Heritage Resources and the National Nuclear Security']\n"
     ]
    }
   ],
   "source": [
    "# View a sample of raw file content\n",
    "print(\"Raw file content (first 5 lines):\")\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"\\t\")\n",
    "    for i, line in enumerate(reader):\n",
    "        if i == 5:  # Limit output to the first 5 lines\n",
    "            break\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Batches of Raw Data:\n",
      "\n",
      "Batch 1:\n",
      "PID: 5216351, Text: This difference between the automatic transmission and CVT is the number of gears. The automatic is limited to 4 to 9 gear ratios and there are definite or noticable changes between the gears and this is felt during driving. The CVT has what is termed an infinite number of ratios ranging from low to high and the transmission move through the gears steeplessly according to the driving situation.\n",
      "PID: 2463607, Text: WILDLIFE Wildlife at Anedodi is abundant and ever surprising! Being fairly remote and surrounded mainly by large oaks, dogwoods, pine, and other forest tree varieties, the possibilities are endless!\n",
      "PID: 2214634, Text: A convenient way to access money. Travellers cheques provide a convenient way to access your money when travelling. By cashing them as you need them, you also minimize the amount of cash you carry around. Denomination Availability. Availability may vary and result in your order not being processed exactly as requested.\n",
      "PID: 1398422, Text: Soldier, Kansas. Soldier is a city in Jackson County, Kansas, United States. As of the 2010 census, the city population was 136.\n",
      "PID: 3389194, Text: Salsa is primarily Cuban son, itself a fusion of Spanish cancion canciÃ³n and guitar And-Afro cuban, percussion merged With North american music styles such as. Jazz salsa also occasionally incorporates elements of, Rock&R, b and. funkhe term salsa was initially promoted and marketed in New York City during the 1970s. Salsa comprises various musical genres including the Cuban son montuno, guaracha, chachacha, chachachÃ¡, mambo and to a certain extent. bolero\n",
      "\n",
      "Batch 2:\n",
      "PID: 941676, Text: The Costs. Minimum cost of bathroom wall tiling: $2.50-$3.00 per square foot. Maximum cost of bathroom wall tiling: $7.00-$8.00 per square foot. When considering a bathroom wall tiling project, homeowners are often most concerned with the costs associated with the installation.With bathroom tiling, costs can vary dramatically depending on the overall quality of the product.aximum cost of bathroom wall tiling: $7.00-$8.00 per square foot. When considering a bathroom wall tiling project, homeowners are often most concerned with the costs associated with the installation.\n",
      "PID: 3673552, Text: COPPA: Children's Online Privacy Protection Act COPPA is enforced by the U.S. Federal Trade Commission. It requires U.S.-based websites that collect personal information from people under the age of 13 to obtain permission from parents or guardians before asking for such data.\n",
      "PID: 597517, Text: Use MSN in a sentence. Most people today are familiar with MSN so if you want your new workers to have a quick learning curve you should use that. Using MSN for all of your computers will keep everyone up to date on the current software and be able to perform different tasks.\n",
      "PID: 3708964, Text: No, DirecTV is not owned by Dish Network. Dish Network is owned by Echostar Communications Corporation, which is headquartered in Englewood, Colorado. Echostar has been aroundâ¦ for about 25 years, and was the first company to offer a satellite receiver for less than $200 and the first to offer a receiver with built-in digital video recording (DVR).\n",
      "PID: 7953238, Text: Celebration in October Join the City of Boerne and the Patrick Heath Public Library for our first-ever Halloween extravaganza! It takes place on the library grounds on Saturday, October 24, from 4:00 PM to 7:00 PM.\n",
      "\n",
      "Batch 3:\n",
      "PID: 6373871, Text: Why You Should Go: Every year Montreal makes this annual ranking of the best places to visit in Canada for one succinct reason: It doesnât disappoint. Montreal is one of the most risk-free choices you can make for a vacation.\n",
      "PID: 8563191, Text: Menopause doesn't cause you to gain weight. But because extra pounds can creep on as women age, a spare tire around the middle has often been dubbed the meno-pot or meno-pudge.. Donât ditch your skinny jeans, though -- here's the truth about this middle-age spread and what you can do about it.\n",
      "PID: 7158266, Text: You should not use methadone if you are allergic to it, or if you have: severe asthma or breathing problems; or. a blockage in your stomach or intestines. Methadone may cause a life-threatening heart rhythm disorder. Your heart function may need to be checked during treatment.\n",
      "PID: 6794180, Text: You can also receive cash back in your PayPal account. There is no annual fee with this card. The PayPal MasterCard is issued by GE Capital Retail Bank. Your APR is either 19.99% for account type I or 23.99% for account type II. The type of account you qualify for depends on your credit worthiness. Your credit score will be used to determine approval along with other information provided in your credit report.\n",
      "PID: 1427393, Text: So, sitting with your legs crossed may not always be bad; itâs the sitting in the same position for hours on end that can be. Fight a sedentary lifestyle by getting up to take walks every half hour, stretching, and focusing on sitting up straight.\n",
      "\n",
      "Batch 4:\n",
      "PID: 8739448, Text: on this website they asked me to put passport issuing authority and i have no idea what that is. Add your answer. Source. Submit Cancel. I think this question violates the Community Guidelines.\n",
      "PID: 6769738, Text: Cereals are a very important food to boost testosterone levels. Cereals are a rich source of vitamins and minerals that are linked with boosting testosterone levels in men. Make sure you make cereal a part of your daily diet.\n",
      "PID: 3213749, Text: [32] Robert Fulton was born at Little Britain, Lancaster County, Pennsylvania, in 1765. His father, though not successful in money matters, was highly respected; he was a leader in the Presbyterian Church, and held a number of minor public offices of honor.\n",
      "PID: 4045332, Text: About the artist. Narcotic Thrust is an electronica/house music duo from the UK consisting of producers Stuart Crichton and Andy Morris. The name Narcotic Thrust is an anagram of Stuart Crichton. Their song Safe From Harm hit #1 on the U.S. Hot Dance Club Play chart in 2002, featuring the lead vocals of Yvonne John Lewis.\n",
      "PID: 3075734, Text: Unique lizard tattoo for women. Â© Forca | Dreamstime.com. Lizard Tattoo Symbolism: 1  Polynesian and Hawaiian population: around here you can find the Lepidodactylus lugubris (this is a type of gecko lizards). 2  Main types of lizards: Gecko, Chameleon, Monitor, etc.3  People usually tattoo themselves with chameleons because they want to blend to people around them. Polynesian and Hawaiian population: around here you can find the Lepidodactylus lugubris (this is a type of gecko lizards). 2  Main types of lizards: Gecko, Chameleon, Monitor, etc. 3  People usually tattoo themselves with chameleons because they want to blend to people around them.\n",
      "\n",
      "Batch 5:\n",
      "PID: 3043510, Text: Page 249 - I left the woods for as good a reason as I went there. Perhaps it seemed to me that I had several more lives to live, and could not spare any more time for that one. It is remarkable how easily and insensibly we fall into a particular route, and make a beaten track for ourselves.\n",
      "PID: 1218632, Text: A plan by the State of California to partially reinstate Medi-Cal funding for dental care could mean a decrease in the number of patients showing up at the clinic with nowhere else to go for dental emergencies. (D. Ross Cameron/Bay Area News Group)\n",
      "PID: 6030788, Text: Microsoft Salary. Microsoft average salary is $92,885, median salary is $88,317 with a salary range from $33,280 to $960,000. Microsoft salaries are collected from government agencies and companies.Each salary is associated with a real job position.icrosoft average salary is $92,885, median salary is $88,317 with a salary range from $33,280 to $960,000.\n",
      "PID: 6962449, Text: IP 101: The Basics of IP Addresses. The IP part of IP address stands for Internet Protocol.. The address part refers to a unique number that gets linked to all online activity you do...somewhat like a return address on a letter you'd send out. (All this happens in milliseconds.) That's the end of today's lesson. At least it should be.\n",
      "PID: 2524772, Text: My wife, Sherrie, and I first attempted to build raised garden beds as a rather desperate means of dealing with a garden site that offered only rocky, dead, chemically abused soil. There was little literature on the subject that we knew of, but we did remember reading that the Chinese have been planting in loosened mounds of earth for 40 centuries.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "raw_data = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"\\t\")\n",
    "    for line in reader:\n",
    "        # Ensure line has both pid and text\n",
    "        if len(line) == 2:\n",
    "            raw_data.append(line)\n",
    "\n",
    "# Display 5 random batches of 5 samples each\n",
    "print(\"Random Batches of Raw Data:\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nBatch {i + 1}:\")\n",
    "    batch = random.sample(raw_data, 5)  # Randomly select 5 samples\n",
    "    for pid, text in batch:\n",
    "        print(f\"PID: {pid}, Text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(doc):    \n",
    "    \"\"\"Returns a string with special characters replaced by whitespaces.\"\"\"\n",
    "    tmp = doc\n",
    "    tmp = tmp.replace(',', ' ')\n",
    "    tmp = tmp.replace('.', ' ')\n",
    "    tmp = tmp.replace('#', ' ')\n",
    "    tmp = tmp.replace('$', ' ')\n",
    "    tmp = tmp.replace('%', ' ')\n",
    "    tmp = tmp.replace('\\n', ' ')\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(doc):    \n",
    "    \"\"\"Returns a sequence of terms given an input text.\"\"\"\n",
    "    return doc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(doc):    \n",
    "    \"\"\"Returns a string with all characters lower-cased.\"\"\"\n",
    "    return doc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'One ring to rule them all. One by one, the free peoples of Middle Earth fell to the power of the Ring. But there were some who resisted.'\n",
    "doc = lowercase(doc)\n",
    "doc = cleanup(doc)\n",
    "tokens = tokenise(doc)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even better tokenizer is the Treebank Word Tokenizer. It incorporates a variety of common rules for English word tokenization. For example, it separates phrase-terminating punctuation (?!.;,) from adjacent tokens and retains decimal numbers containing a period as a single token. In addition it contains rules for English contractions. For example “don’t” is tokenized as [\"do\", \"n’t\"].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(cleanup(sentence))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function works well for regular cases, but is unable to address more complex cases.\n",
    "Two of the most popular stemming algorithms are the **Porter** and **Snowball** stemmers. These stemmers implement more complex rules than our simple regular expression. This enables the stemmer to handle the complexities of English spelling and word ending rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "print(' '.join([stemmer.stem(w).strip(\"'\") for w in \"dish washer's washed dishes\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/elahe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Processing Documents: 8841823it [1:10:51, 2079.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to preprocessed_data.json\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define helper functions\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphanumeric characters (keeping ASCII letters and spaces)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Apply stemming\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# File paths\n",
    "tar_path = \"/home/elahe/Desktop/UniPisa/IR/TinTinfy/collection.tar.gz\"  # Update with your file path\n",
    "output_file = \"preprocessed_data.json\"\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "    tar.extractall()\n",
    "\n",
    "# Process the extracted file\n",
    "input_file = \"collection.tsv\"  # The extracted file name\n",
    "preprocessed_data = []\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=\"\\t\")\n",
    "    for line in tqdm(reader, desc=\"Processing Documents\"):\n",
    "        try:\n",
    "            # Ensure line has both pid and text\n",
    "            if len(line) != 2:\n",
    "                continue\n",
    "            pid, text = line\n",
    "            # Preprocess the text\n",
    "            cleaned_text = preprocess_text(text)\n",
    "            # Skip empty or too short documents\n",
    "            if len(cleaned_text.split()) < 5:\n",
    "                continue\n",
    "            # Append to result\n",
    "            preprocessed_data.append({\"pid\": pid, \"text\": cleaned_text})\n",
    "        except Exception as e:\n",
    "            # Log and skip malformed lines\n",
    "            print(f\"Error processing line: {line} - {e}\")\n",
    "\n",
    "# Save preprocessed data\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    json.dump(preprocessed_data, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Preprocessed data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develop-57Ft6pto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
